{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET ID to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP THE DIRECTORY\n",
    "dir_to_eval = '/root/test'\n",
    "id_to_eval = 1451 # give the ID HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path_for_id_gt = os.path.join(dir_to_eval, 'gt', str(id_to_eval))\n",
    "full_path_for_id_pseudo = os.path.join(dir_to_eval, 'pseudo', str(id_to_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP feature similarity averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE SIMILARITY:  tensor([0.8662], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# from locale import normalize\n",
    "sim=0\n",
    "with torch.no_grad():\n",
    "    for idx in range(1, 6):\n",
    "        tmp_gt = os.path.join(full_path_for_id_gt, str(idx)+'.png')\n",
    "        tmp_ps = os.path.join(full_path_for_id_pseudo, str(idx)+'.png')\n",
    "        im_gt = Image.open(tmp_gt)\n",
    "        im_ps = Image.open(tmp_ps)\n",
    "        \n",
    "        # im_gt = im_gt / 256\n",
    "        # im_ps = im_ps / 256\n",
    "        im_gt = preprocess(im_gt).unsqueeze(0).to(device)\n",
    "        im_ps = preprocess(im_ps).unsqueeze(0).to(device)\n",
    "        # print(im_gt.shape, im_ps.shape)\n",
    "        \n",
    "        gt_ft = model.encode_image(im_gt)\n",
    "        ps_ft = model.encode_image(im_ps)\n",
    "        \n",
    "        sim += F.cosine_similarity(gt_ft, ps_ft)\n",
    "        \n",
    "        \n",
    "print('AVERAGE SIMILARITY: ', sim/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK direction similarity in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE DIFF_SIMILARITY:  tensor([-0.0054], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# from locale import normalize\n",
    "sim=0\n",
    "with torch.no_grad():\n",
    "    for idx in range(1, 5):\n",
    "        tmp_gt = os.path.join(full_path_for_id_gt, str(idx)+'.png')\n",
    "        tmp_ps = os.path.join(full_path_for_id_pseudo, str(idx)+'.png')\n",
    "        tmp_gt_next = os.path.join(full_path_for_id_gt, str(idx+1)+'.png')\n",
    "        tmp_ps_next = os.path.join(full_path_for_id_pseudo, str(idx+1)+'.png')\n",
    "        im_gt = Image.open(tmp_gt)\n",
    "        im_ps = Image.open(tmp_ps)\n",
    "        im_gt_n = Image.open(tmp_gt_next)\n",
    "        im_ps_n = Image.open(tmp_ps_next)\n",
    "        \n",
    "        # im_gt = im_gt / 256\n",
    "        # im_ps = im_ps / 256\n",
    "        im_gt = preprocess(im_gt).unsqueeze(0).to(device)\n",
    "        im_ps = preprocess(im_ps).unsqueeze(0).to(device)\n",
    "        im_gt_n = preprocess(im_gt_n).unsqueeze(0).to(device)\n",
    "        im_ps_n = preprocess(im_ps_n).unsqueeze(0).to(device)\n",
    "        # print(im_gt.shape, im_ps.shape)\n",
    "        \n",
    "        gt_ft = model.encode_image(im_gt)\n",
    "        ps_ft = model.encode_image(im_ps)\n",
    "        \n",
    "        gt_ft_n = model.encode_image(im_gt_n)\n",
    "        ps_ft_n = model.encode_image(im_ps_n)\n",
    "        \n",
    "        gt_diff = gt_ft_n - gt_ft\n",
    "        ps_diff = ps_ft_n - ps_ft\n",
    "        \n",
    "        sim += F.cosine_similarity(gt_diff, ps_diff)\n",
    "        \n",
    "        \n",
    "print('AVERAGE DIFF_SIMILARITY: ', sim/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
